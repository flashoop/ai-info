{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3310783,"sourceType":"datasetVersion","datasetId":2002344}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport subprocess\nimport sys\n\n# 动态安装缺失的库\ndef install(package):\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n\ntry:\n    import splitfolders\nexcept ImportError:\n    print(\"正在安装 split-folders...\")\n    install('split-folders')\n    import splitfolders\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-26T11:26:17.494739Z","iopub.execute_input":"2026-01-26T11:26:17.495101Z","iopub.status.idle":"2026-01-26T11:26:22.215757Z","shell.execute_reply.started":"2026-01-26T11:26:17.495074Z","shell.execute_reply":"2026-01-26T11:26:22.214997Z"}},"outputs":[{"name":"stdout","text":"正在安装 split-folders...\nCollecting split-folders\n  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\nDownloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\nInstalling collected packages: split-folders\nSuccessfully installed split-folders-0.5.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import splitfolders\n\nDATA_BASE_PATH = \"/kaggle/input/malimg-original/malimg_paper_dataset_imgs\"\nTARGET_BASE_PATH = \"./newdata/\"\n\nTRAINING_RATIO = 0.8\nTEST_RATIO = 1 - TRAINING_RATIO\n\nsplitfolders.ratio(input=DATA_BASE_PATH, output=TARGET_BASE_PATH, ratio=(TRAINING_RATIO, 0, TEST_RATIO))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-26T11:26:24.038756Z","iopub.execute_input":"2026-01-26T11:26:24.039364Z","iopub.status.idle":"2026-01-26T11:27:05.941455Z","shell.execute_reply.started":"2026-01-26T11:26:24.039334Z","shell.execute_reply":"2026-01-26T11:27:05.940799Z"}},"outputs":[{"name":"stderr","text":"Copying files: 9339 files [00:41, 223.00 files/s]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"After combining the above code into a single function, we end up with the following code:\n\n","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport os\n\ndef load_datasets(base_path, train_batch_size, test_batch_size):\n    # Define preprocessing transforms\n    transform = transforms.Compose([\n        transforms.Resize((75, 75)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    # Load training and test datasets\n    train_dataset = ImageFolder(\n        root=os.path.join(base_path, \"train\"),\n        transform=transform\n    )\n\n    test_dataset = ImageFolder(\n        root=os.path.join(base_path, \"test\"),\n        transform=transform\n    )\n\n    # Create data loaders\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=train_batch_size,\n        shuffle=True,\n        num_workers=2\n    )\n    \n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=test_batch_size,\n        shuffle=False,\n        num_workers=2\n    )\n\n    n_classes = len(train_dataset.classes)\n    return train_loader, test_loader, n_classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-26T11:29:32.521167Z","iopub.execute_input":"2026-01-26T11:29:32.522025Z","iopub.status.idle":"2026-01-26T11:29:40.178105Z","shell.execute_reply.started":"2026-01-26T11:29:32.521993Z","shell.execute_reply":"2026-01-26T11:29:40.177358Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"The model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torchvision.models as models\n\nHIDDEN_LAYER_SIZE = 1000\n\nclass MalwareClassifier(nn.Module):\n    def __init__(self, n_classes):\n        super(MalwareClassifier, self).__init__()\n        # Load pretrained ResNet50\n        self.resnet = models.resnet50(weights='DEFAULT')\n        \n        # Freeze ResNet parameters\n        for param in self.resnet.parameters():\n            param.requires_grad = False\n        \n        # Replace the last fully connected layer\n        num_features = self.resnet.fc.in_features\n        self.resnet.fc = nn.Sequential(\n            nn.Linear(num_features, HIDDEN_LAYER_SIZE),\n            nn.ReLU(),\n            nn.Linear(HIDDEN_LAYER_SIZE, n_classes)\n        )\n\n    def forward(self, x):\n        return self.resnet(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-26T11:29:44.421403Z","iopub.execute_input":"2026-01-26T11:29:44.422110Z","iopub.status.idle":"2026-01-26T11:29:44.427550Z","shell.execute_reply.started":"2026-01-26T11:29:44.422079Z","shell.execute_reply":"2026-01-26T11:29:44.426886Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/working/newdata\"\nTRAINING_BATCH_SIZE = 1024\nTEST_BATCH_SIZE = 1024\n\n# Load datasets\ntrain_loader, test_loader, n_classes = load_datasets(DATA_PATH, TRAINING_BATCH_SIZE, TEST_BATCH_SIZE)\n\n# Initialize model\nmodel = MalwareClassifier(n_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-26T10:59:21.423110Z","iopub.execute_input":"2026-01-26T10:59:21.423922Z","iopub.status.idle":"2026-01-26T10:59:22.679075Z","shell.execute_reply.started":"2026-01-26T10:59:21.423886Z","shell.execute_reply":"2026-01-26T10:59:22.677968Z"}},"outputs":[{"name":"stdout","text":"Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 97.8M/97.8M [00:00<00:00, 180MB/s]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"The final training function looks like this:\n\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport time\n\ndef train(model, train_loader, n_epochs, verbose=False):\n    model.train()\n    criterion = torch.nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters())\n\n    training_data = {\"accuracy\": [], \"loss\": []}\n    \n    for epoch in range(n_epochs):\n        running_loss = 0\n        n_total = 0\n        n_correct = 0\n        checkpoint = time.time() * 1000\n        \n        for inputs, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            _, predicted = outputs.max(1)\n            n_total += labels.size(0)\n            n_correct += predicted.eq(labels).sum().item()\n            running_loss += loss.item()\n        \n        epoch_loss = running_loss / len(train_loader)\n        epoch_duration = int(time.time() * 1000 - checkpoint)\n        epoch_accuracy = compute_accuracy(n_correct, n_total)\n        \n        training_data[\"accuracy\"].append(epoch_accuracy)\n        training_data[\"loss\"].append(epoch_loss)\n        \n        if verbose:\n            print(f\"[i] Epoch {epoch+1} of {n_epochs}: Acc: {epoch_accuracy:.2f}% Loss: {epoch_loss:.4f} (Took {epoch_duration} ms).\")    \n    \n    return training_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-26T11:29:49.234029Z","iopub.execute_input":"2026-01-26T11:29:49.234318Z","iopub.status.idle":"2026-01-26T11:29:49.242805Z","shell.execute_reply.started":"2026-01-26T11:29:49.234294Z","shell.execute_reply":"2026-01-26T11:29:49.241864Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"save model ","metadata":{}},{"cell_type":"code","source":"def save_model(model, path):\n\tmodel_scripted = torch.jit.script(model)\n\tmodel_scripted.save(path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-26T11:29:52.970371Z","iopub.execute_input":"2026-01-26T11:29:52.971161Z","iopub.status.idle":"2026-01-26T11:29:52.975231Z","shell.execute_reply.started":"2026-01-26T11:29:52.971128Z","shell.execute_reply":"2026-01-26T11:29:52.974396Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Evaluation","metadata":{}},{"cell_type":"code","source":"def predict(model, test_data):\n    model.eval()\n\n    with torch.no_grad():\n        output = model(test_data)\n        _, predicted = torch.max(output.data, 1)\n\n    return predicted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-26T11:29:57.537458Z","iopub.execute_input":"2026-01-26T11:29:57.537765Z","iopub.status.idle":"2026-01-26T11:29:57.542389Z","shell.execute_reply.started":"2026-01-26T11:29:57.537740Z","shell.execute_reply":"2026-01-26T11:29:57.541535Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"evaluation","metadata":{}},{"cell_type":"code","source":"def compute_accuracy(n_correct, n_total):\n    return round(100 * n_correct / n_total, 2)\n\n\ndef evaluate(model, test_loader):\n    model.eval()\n\n    n_correct = 0\n    n_total = 0\n    \n    with torch.no_grad():\n        for data, target in test_loader:\n            predicted = predict(model, data)\n            n_total += target.size(0)\n            n_correct += (predicted == target).sum().item()\n\n    accuracy = compute_accuracy(n_correct, n_total)  \n\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-26T11:29:59.897998Z","iopub.execute_input":"2026-01-26T11:29:59.898335Z","iopub.status.idle":"2026-01-26T11:29:59.904215Z","shell.execute_reply.started":"2026-01-26T11:29:59.898307Z","shell.execute_reply":"2026-01-26T11:29:59.903351Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"Plots","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot(data, title, label, xlabel, ylabel):\n    # HTB Color Palette\n    htb_green = \"#9FEF00\"\n    node_black = \"#141D2B\"\n    hacker_grey = \"#A4B1CD\"\n\n    # plot\n    plt.figure(figsize=(10, 6), facecolor=node_black)\n    plt.plot(range(1, len(data)+1), data, label=label, color=htb_green)\n    plt.title(title, color=htb_green)\n    plt.xlabel(xlabel, color=htb_green)\n    plt.ylabel(ylabel, color=htb_green)\n    plt.xticks(color=hacker_grey)\n    plt.yticks(color=hacker_grey)\n    ax = plt.gca()\n    ax.set_facecolor(node_black)\n    ax.spines['bottom'].set_color(hacker_grey)\n    ax.spines['top'].set_color(node_black)\n    ax.spines['right'].set_color(node_black)\n    ax.spines['left'].set_color(hacker_grey)\n\n    legend = plt.legend(facecolor=node_black, edgecolor=hacker_grey, fontsize=10)\n    plt.setp(legend.get_texts(), color=htb_green)\n    \n    plt.show()\n\ndef plot_training_accuracy(training_data):\n    plot(training_data['accuracy'], \"Training Accuracy\", \"Accuracy\", \"Epoch\", \"Accuracy (%)\")\n\ndef plot_training_loss(training_data):\n    plot(training_data['loss'], \"Training Loss\", \"Loss\", \"Epoch\", \"Loss\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-26T11:30:05.315034Z","iopub.execute_input":"2026-01-26T11:30:05.315760Z","iopub.status.idle":"2026-01-26T11:30:05.322587Z","shell.execute_reply.started":"2026-01-26T11:30:05.315731Z","shell.execute_reply":"2026-01-26T11:30:05.321829Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"Running the Code\nAfter defining all helper functions, we can write a script that defines all parameters and runs the helper functions to load the data, initialize the model, train the model, save the model, and finally evaluate the model:","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# data parameters\nDATA_PATH = \"/kaggle/working/newdata\"\n\n# training parameters\nN_EPOCHS = 10\nTRAINING_BATCH_SIZE = 512\nTEST_BATCH_SIZE = 1024\n\n# model parameters\nHIDDEN_LAYER_SIZE = 1000\nMODEL_FILE = \"malware_classifier.pth\"\n\n\n# Load datasets\ntrain_loader, test_loader, n_classes = load_datasets(DATA_PATH, TRAINING_BATCH_SIZE, TEST_BATCH_SIZE)\n\n# Initialize model\nmodel = MalwareClassifier(n_classes)\n\n# Train model\nprint(\"[i] Starting Training...\")  \ntraining_information = train(model, train_loader, N_EPOCHS, verbose=True)\n\n# Save model\nsave_model(model, MODEL_FILE)\n\n# evaluate model\naccuracy = evaluate(model, test_loader)\nprint(f\"[i] Inference accuracy: {accuracy}%.\")  \n\n# Plot training details\nplot_training_accuracy(training_information)\nplot_training_loss(training_information)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-26T11:30:09.108346Z","iopub.execute_input":"2026-01-26T11:30:09.109055Z","execution_failed":"2026-01-26T11:31:55.157Z"}},"outputs":[{"name":"stdout","text":"Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 97.8M/97.8M [00:00<00:00, 190MB/s]\n","output_type":"stream"},{"name":"stdout","text":"[i] Starting Training...\n","output_type":"stream"}],"execution_count":null}]}