{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aae9152",
   "metadata": {},
   "source": [
    "Downloading the Dataset\n",
    "The first step in our process is to download this dataset, and we'll do it programmatically in our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fe0f99b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mzipfile\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mio\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'requests'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "# URL of the dataset\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "# Download the dataset\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    print(\"Download successful\")\n",
    "else:\n",
    "    print(\"Failed to download the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33cb9a4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'zipfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Extract the dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m.ZipFile(io.BytesIO(response.content)) \u001b[38;5;28;01mas\u001b[39;00m z:\n\u001b[32m      3\u001b[39m     z.extractall(\u001b[33m\"\u001b[39m\u001b[33msms_spam_collection\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExtraction successful\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'zipfile' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract the dataset\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "    z.extractall(\"sms_spam_collection\")\n",
    "    print(\"Extraction successful\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f18043",
   "metadata": {},
   "source": [
    "Here, response.content contains the binary data of the downloaded .zip file. We use io.BytesIO to convert this binary data into a bytes-like object that can be processed by zipfile.ZipFile. The extractall method extracts all files from the archive into a specified directory, in this case, sms_spam_collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "861aa899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files: ['readme', 'SMSSpamCollection']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List the extracted files\n",
    "extracted_files = os.listdir(\"sms_spam_collection\")\n",
    "print(\"Extracted files:\", extracted_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd288ce2",
   "metadata": {},
   "source": [
    "Loading the Dataset\n",
    "\n",
    "With the dataset extracted, we can now load it into a pandas DataFrame for further analysis. The SMS Spam Collection dataset is stored in a tab-separated values (TSV) file format, which we specify using the sep parameter in pd.read_csv.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b103160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\n",
    "    \"sms_spam_collection/SMSSpamCollection\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"label\", \"message\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ca95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- HEAD --------------------\n",
      "  label                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "-------------------- DESCRIBE --------------------\n",
      "       label                 message\n",
      "count   5572                    5572\n",
      "unique     2                    5169\n",
      "top      ham  Sorry, I'll call later\n",
      "freq    4825                      30\n",
      "-------------------- INFO --------------------\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   label    5572 non-null   str  \n",
      " 1   message  5572 non-null   str  \n",
      "dtypes: str(2)\n",
      "memory usage: 87.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"-------------------- HEAD --------------------\")\n",
    "print(df.head())\n",
    "print(\"-------------------- DESCRIBE --------------------\")\n",
    "print(df.describe())\n",
    "print(\"-------------------- INFO --------------------\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16883d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " label      0\n",
      "message    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb6e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(\"Duplicate entries:\", df.duplicated().sum())\n",
    "\n",
    "# Remove duplicates if any\n",
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5c2bf0",
   "metadata": {},
   "source": [
    "*** Section 2 *** \n",
    "\n",
    "\n",
    "Preprocessing the Spam Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf40c74",
   "metadata": {},
   "source": [
    "Lowercasing the Text\n",
    "Lowercasing the text ensures that the classifier treats words equally, regardless of their original casing. By converting all characters to lowercase, the model considers \"Free\" and \"free\" as the same token, effectively reducing dimensionality and improving consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f0d14",
   "metadata": {},
   "source": [
    "Removing Punctuation and Numbers\n",
    "Removing unnecessary punctuation and numbers simplifies the dataset by focusing on meaningful words. However, certain symbols such as $ and ! may contain important context in spam messages. For example, $ might indicate a monetary amount, and ! might add emphasis.\n",
    "\n",
    "The code below removes all characters other than lowercase letters, whitespace, dollar signs, or exclamation marks. This balance between cleaning the data and preserving important symbols helps the model concentrate on features relevant to distinguishing spam from ham messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0d051a",
   "metadata": {},
   "source": [
    "Tokenizing the Text\n",
    "Tokenization divides the message text into individual words or tokens, a crucial step before further analysis. By converting unstructured text into a sequence of words, we prepare the data for operations like removing stop words and applying stemming. Each token corresponds to a meaningful unit, allowing downstream processes to operate on smaller, standardized elements rather than entire sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62477b9d",
   "metadata": {},
   "source": [
    "Removing Stop Words\n",
    "Stop words are common words like and, the, or is that often do not add meaningful context. Removing them reduces noise and focuses the model on the words most likely to help distinguish spam from ham messages. By reducing the number of non-informative tokens, we help the model learn more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e55eec",
   "metadata": {},
   "source": [
    "Stemming\n",
    "Stemming normalizes words by reducing them to their base form (e.g., running becomes run). This consolidates different forms of the same root word, effectively cutting the vocabulary size and smoothing out the text representation. As a result, the model can better understand the underlying concepts without being distracted by trivial variations in word forms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d4de77",
   "metadata": {},
   "source": [
    "Joining Tokens Back into a Single String\n",
    "While tokens are useful for manipulation, many machine-learning algorithms and vectorization techniques (e.g., TF-IDF) work best with raw text strings. Rejoining the tokens into a space-separated string restores a format compatible with these methods, allowing the dataset to move seamlessly into the feature extraction phase"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
